<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>K3s Cluster With Vsphere Storage [Part III] | DODBRIT</title><meta name=keywords content="Rancher,Kubernetes,Storage,K3S,VMWare"><meta name=description content="Having followed the steps in Part II, you should have a K3S Cluster stood up. In this Part we are going to add the all important Cloud Provider.
Step 1: Prepare Nodes for vSphere Cloud Provider Before we can install the vSphere Cloud provider, there are couple configurations that need to be applied. You can read more about these requirements by heading over to the VMWare documentation.
Taint Nodes The Cloud Provider is going to be installed on the Server (Master) Nodes."><meta name=author content="Peter Keech"><link rel=canonical href=https://dodbrit.io/posts/2021-07-03/k3s-cluster-with-vsphere-storage-part-iii/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://dodbrit.io/images/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dodbrit.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dodbrit.io/favicon-32x32.png><link rel=apple-touch-icon href=https://dodbrit.io/apple-touch-icon.png><link rel=mask-icon href=https://dodbrit.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="K3s Cluster With Vsphere Storage [Part III]"><meta property="og:description" content="Having followed the steps in Part II, you should have a K3S Cluster stood up. In this Part we are going to add the all important Cloud Provider.
Step 1: Prepare Nodes for vSphere Cloud Provider Before we can install the vSphere Cloud provider, there are couple configurations that need to be applied. You can read more about these requirements by heading over to the VMWare documentation.
Taint Nodes The Cloud Provider is going to be installed on the Server (Master) Nodes."><meta property="og:type" content="article"><meta property="og:url" content="https://dodbrit.io/posts/2021-07-03/k3s-cluster-with-vsphere-storage-part-iii/"><meta property="og:image" content="https://dodbrit.io/thumbnails/k3s-vsphere-part3.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-07-03T02:00:00+00:00"><meta property="article:modified_time" content="2021-07-03T02:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dodbrit.io/thumbnails/k3s-vsphere-part3.png"><meta name=twitter:title content="K3s Cluster With Vsphere Storage [Part III]"><meta name=twitter:description content="Having followed the steps in Part II, you should have a K3S Cluster stood up. In this Part we are going to add the all important Cloud Provider.
Step 1: Prepare Nodes for vSphere Cloud Provider Before we can install the vSphere Cloud provider, there are couple configurations that need to be applied. You can read more about these requirements by heading over to the VMWare documentation.
Taint Nodes The Cloud Provider is going to be installed on the Server (Master) Nodes."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://dodbrit.io/posts/"},{"@type":"ListItem","position":3,"name":"K3s Cluster With Vsphere Storage [Part III]","item":"https://dodbrit.io/posts/2021-07-03/k3s-cluster-with-vsphere-storage-part-iii/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"K3s Cluster With Vsphere Storage [Part III]","name":"K3s Cluster With Vsphere Storage [Part III]","description":"Having followed the steps in Part II, you should have a K3S Cluster stood up. In this Part we are going to add the all important Cloud Provider.\nStep 1: Prepare Nodes for vSphere Cloud Provider Before we can install the vSphere Cloud provider, there are couple configurations that need to be applied. You can read more about these requirements by heading over to the VMWare documentation.\nTaint Nodes The Cloud Provider is going to be installed on the Server (Master) Nodes.","keywords":["Rancher","Kubernetes","Storage","K3S","VMWare"],"articleBody":"Having followed the steps in Part II, you should have a K3S Cluster stood up. In this Part we are going to add the all important Cloud Provider.\nStep 1: Prepare Nodes for vSphere Cloud Provider Before we can install the vSphere Cloud provider, there are couple configurations that need to be applied. You can read more about these requirements by heading over to the VMWare documentation.\nTaint Nodes The Cloud Provider is going to be installed on the Server (Master) Nodes. To ensure this happens correctly, we need to ensure the nodes are tainted correctly.\nInfo\nNot sure if this is a K3S quirk or just my luck, but additionally I had to reapply the Master and Worker roles to the Nodes for the DaemonSet to recognize the Role.\n## TAINT SERVER (MASTER) NODES kubectl taint nodes --selector='node-role.kubernetes.io/master' node-role.kubernetes.io/master=:NoSchedule ## ADD ROLES TO SERVER (MASTER) NODES kubectl label nodes --selector='node-role.kubernetes.io/master' node-role.kubernetes.io/master= --overwrite ## TAINT AGENT (WORKER) NODES kubectl taint nodes --selector='!node-role.kubernetes.io/master' node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule ## ADD ROLES TO AGENT (WORKER) NODES kubectl label nodes --selector='node-role.kubernetes.io/worker' node-role.kubernetes.io/worker= --overwrite Once you have applied the Taints, you can verify they applied successfully by running this command;\n## VALIDATE TAINTS kubectl describe nodes | egrep \"Taints:|Name:\" If the taints applied successfully you should see all the Server (Master) Nodes with the Taint node-role.kubernetes.io/master:NoSchedule and all Agent (Worker) Nodes have the Taint node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule\nConfigure Virtual Machine Settings Another configuration item that needs to occur, is ensuring that each virtual machine’s hard disk (vmdk) is assigned a unique identifier (UUID). The easiest way to interact with the virtual machine settings is to use a command line utility called govc.\ngovc is vSphere CLI provided by VMware and is built on top of govmoi. The CLI is designed to be a user friendly CLI alternative to the GUI and well suited for automation tasks. It also acts as a test harness for the govmomi APIs and provides working examples of how to use the APIs.\n– Govc Github\nTo install the CLI on Mac, you can use Homebrew. To install govc run brew install govc. For other operating systems, please refer to the documentation.\nGOVC Setup Before we can use the utility we have to specify how govc connects to vSphere. In Mac and Linux, this is accomplished by setting environment variables.\n## CONFIGURE GOVC export GOVC_URL='{{ URL-FOR-VCSA }}' export GOVC_USERNAME='administrator@vsphere.local' export GOVC_PASSWORD='{{ PASSWORD-FOR-ABOVE-ACCOUNT }}' export GOVC_INSECURE=1 Variable Description GOVC_URL the URL for your vSphere (VCSA) instance GOVC_USERNAME the login account for vSphere GOVC_PASSWORD the password for the account specified GOVC_INSECURE used when self-signed certificates are in use on VCSA, suppresses certificate warnings Enable DiskUUID At this point you should be able to utilize govc to query vSphere. The first command you can run is govc ls. This will list the any DataCenters you have configured and folders. You will need to enable DiskUUID on all the virtual machines in the cluster and to do this you will need to know the path to the virtual machine.\nTo find the path use the govc ls command followed by a path. Start with leaving it blank and keep drilling down until you find the paths to your virtual machines. For the example below, my final govc command looked like; govc ls /Homelab/vm/Applications/Demo/\nEnable DiskUUID on the virtual machines by running the following command. Outline below is how I applied it in my stack.\n## ADD DISK UUID FLAG govc vm.change -e=\"disk.enableUUID=1\" -vm='{{ PATH-TO-VM }}' ## EXAMPLE -- ADD DISK UUID govc vm.change -e=\"disk.enableUUID=1\" -vm='/Homelab/vm/Applications/Demo/MASTER-001' govc vm.change -e=\"disk.enableUUID=1\" -vm='/Homelab/vm/Applications/Demo/MASTER-002' govc vm.change -e=\"disk.enableUUID=1\" -vm='/Homelab/vm/Applications/Demo/MASTER-003' govc vm.change -e=\"disk.enableUUID=1\" -vm='/Homelab/vm/Applications/Demo/WORKER-001' govc vm.change -e=\"disk.enableUUID=1\" -vm='/Homelab/vm/Applications/Demo/WORKER-002' govc vm.change -e=\"disk.enableUUID=1\" -vm='/Homelab/vm/Applications/Demo/WORKER-003' Adding ProviderID The final configuration change needed is to add a “ProviderID” to each of the nodes. Reading though the documentation, this ID needs to be unique but can be set to anything (within reason). Borrowing from the documentation, the easiest thing to do is to assign the virtual machine UUID as the ProviderID as these are always unique.\n## ADD PROVIDERID TO EACH NODE for vm in $(govc ls /Homelab/vm/Applications/Demo/); do MACHINE_INFO=$(govc vm.info -json -dc=Homelab -vm.ipath=\"$vm\" -e=true) VM_NAME=$(jq -r ' .VirtualMachines[] | .Name' \u003c\u003c\u003c $MACHINE_INFO | awk '{print tolower($0)}') VM_UUID=$( jq -r ' .VirtualMachines[] | .Config.Uuid' \u003c\u003c\u003c $MACHINE_INFO | awk '{print toupper($0)}') kubectl patch node $VM_NAME.dodbrit.lab -p \"{\\\"spec\\\":{\\\"providerID\\\":\\\"vsphere://$VM_UUID\\\"}}\"; done For good measure, you can validate that the ProviderIDs were added correctly by running kubectl describe nodes | egrep \"ProviderID:|Name:\". The expected outcome should be all of the nodes listed, with a ProviderID that starts with “vsphere”. Additionally, the IDs should all be unique.\nStep 2: Install vSphere CPI Now that we have our cluster up and running, and the nodes configured with additional information, we can finally install the vSphere Cloud Provider.\nThe first step is generate the required configuration file (vsphere.conf) and credentials (cpi-secret.yaml).\n# vsphere.conf # Global properties in this section will be used for all specified vCenters unless overriden in VirtualCenter section. global: # default https port port: 443 # set insecureFlag to true if the vCenter uses a self-signed cert insecureFlag: true # settings for using k8s secret secretName: cpi-global-secret secretNamespace: kube-system # vcenter section vcenter: # arbitrary name for cluster demo: # ip or fqdn of vcsa server: 10.0.15.5 # vSphere Datacenter Name datacenters: - Homelab # secret with credentials secretName: cpi-secret secretNamespace: kube-system # cpi-secret.yaml apiVersion: v1 kind: Secret metadata: name: cpi-secret namespace: kube-system stringData: 10.0.15.5.username: \"administrator@vsphere.local\" 10.0.15.5.password: \"{{ PASSWORD-TO-ACCOUNT }}\" To apply the vSphere configuration to the cluster, we will create a ConfigMap of the file. To do that you run the following command;\nkubectl create configmap cloud-config --from-file=vsphere.conf --namespace=kube-system This will create a ConfigMap in the kube-system namespace with all the items we defined. To add the login credentials, we just need to apply the Secret as that was defined as a Secret to begin with.\nkubectl create -f cpi-secret.yaml Again for peace of mind, we can validate these applied;\n## ENSURE CONFIGMAP WAS CREATED kubectl get configmap cloud-config --namespace=kube-system ## ENSURE SECRET WAS CREATED kubectl get secret cpi-secret --namespace=kube-system After you have verified that the ConfigMap and Secret was created, you can delete both of these files. These files have potentially sensitive information in them and its good practice to remove them.\nNow we can deploy all the components of the vSphere Cloud Provider. We are going to apply them directly from the vSphere GitHub repository.\nNote\nIt is recommend that you review the files first and once you feel confident that the files are safe, you can then apply them\n## CREATE ROLES kubectl apply -f https://raw.githubusercontent.com/kubernetes/cloud-provider-vsphere/master/manifests/controller-manager/cloud-controller-manager-roles.yaml ## CREATE ROLE BINDINGS kubectl apply -f https://raw.githubusercontent.com/kubernetes/cloud-provider-vsphere/master/manifests/controller-manager/cloud-controller-manager-role-bindings.yaml ## CREATE DAMEONSET kubectl apply -f https://github.com/kubernetes/cloud-provider-vsphere/raw/master/manifests/controller-manager/vsphere-cloud-controller-manager-ds.yaml And we can check that the Cloud Provider deployed successfully. You should see a vsphere-cloud-controller-manager running on each of your master nodes.\nkubectl get pods --all-namespaces Congratulations! We have just install the vSphere Cloud Provider within our cluster!\nStep 3: Install vSphere CSI Now that the Cloud Provider has been installed, we can turn the attention to the Cloud Storage Interface (CSI). Just like the Cloud Provider, we need to create some configuration files. Modify the file outlined below and save it as csi-vsphere.conf.\n[Global] cluster-id = \"k3s-cluster\" user = \"administrator@vsphere.local\" password = \"{{ PASSWORD-FOR-ACCOUNT }}\" port = \"443\" insecure-flag = \"1\" [VirtualCenter \"{{ VCSA-IP-ADDRESS }}\"] datacenters = \"Homelab\" [Workspace] server = \"{{ VCSA-IP-ADDRESS }}\" datacenter = \"Homelab\" default-datastore = \"{{ DEFAULT-VSPHERE-DATASTORE }}\" resourcepool-path = \"{{ DATACENTER-NAME }}/Resources\" folder = \"kubernetes\" [Disk] scsicontrollertype = pvscsi The default-datastore field in the configuration file is important enough that it is included in the file, but will not be used once we configure the Storage Class. The Storage Class grants us the ability to define where the persistent storage will be save. Additionally, multiple Storage Class‘s can be defined that will allow for more granular storage based upon the deployment.\nUnlike CPI, we are going to upload this configuration to Kubernetes via a Secret.\nkubectl create secret generic vsphere-config-secret --from-file=csi-vsphere.conf --namespace=kube-system When then validate that the Secret created successfully …\nkubectl get secret vsphere-config-secret --namespace=kube-system Note\nAt this point, you made delete csi-vsphere.conf as it contains sensitive information.\nNow we can deploy all the components of the vSphere Storage Provider. We are going to apply them directly from the vSphere GitHub repository.\n## DEFINE CLUSTER ROLES kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/vsphere-csi-driver/v2.2.0/manifests/v2.2.0/rbac/vsphere-csi-controller-rbac.yaml ## DEFINE ROLE BINDINGS kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/vsphere-csi-driver/v2.2.0/manifests/v2.2.0/rbac/vsphere-csi-node-rbac.yaml ## DEPLOY STORAGE DRIVERS (CONTROLLER) kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/vsphere-csi-driver/v2.2.0/manifests/v2.2.0/deploy/vsphere-csi-controller-deployment.yaml ## DEPLOY STORAGE DRIVERS (DAMEONSET) kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/vsphere-csi-driver/v2.2.0/manifests/v2.2.0/deploy/vsphere-csi-node-ds.yaml We can then validate the installation by checking the Pod deployment. It may take a few minutes for all of the pods to get created and start running.\nkubectl get pods --namespace=kube-system Summary At this point, and ensuring that everything went smoothly, you should have a Kubernetes cluster running with both vSphere CPI and CSI running and configured. In Part IV of this blog, we are going to define the storage class within the cluster and deploy a demo application.\nReferences Rancher Labs Longhorn vSphere Cloud Provider vSphere Storage Provider Rancher Labs K3S Kuberenetes Cloud Controllers VMware Photon OS NGINX Load Balancer Govc Documentation ","wordCount":"1515","inLanguage":"en","image":"https://dodbrit.io/thumbnails/k3s-vsphere-part3.png","datePublished":"2021-07-03T02:00:00Z","dateModified":"2021-07-03T02:00:00Z","author":[{"@type":"Person","name":"Peter Keech"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://dodbrit.io/posts/2021-07-03/k3s-cluster-with-vsphere-storage-part-iii/"},"publisher":{"@type":"Organization","name":"DODBRIT","logo":{"@type":"ImageObject","url":"https://dodbrit.io/images/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dodbrit.io accesskey=h title="DODBRIT (Alt + H)">DODBRIT</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dodbrit.io/posts/ title=Blog><span>Blog</span></a></li><li><a href=https://dodbrit.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dodbrit.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://dodbrit.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://dodbrit.io/about/ title="About Me"><span>About Me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>K3s Cluster With Vsphere Storage [Part III]</h1><div class=post-meta><span title='2021-07-03 02:00:00 +0000 UTC'>July 3, 2021</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Peter Keech&nbsp;|&nbsp;<a href=https://github.com/dodbrit/blog/content/posts/2021-07-03/k3s-cluster-with-vsphere-storage-part-iii.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=lazy src=https://dodbrit.io/thumbnails/k3s-vsphere-part3.png alt="K3S Cluster with vSphere Storage [Part III]"><p>K3S Cluster with vSphere Storage [Part III]</p></figure><div class=post-content><p>Having followed the steps in <a href=../k3s-cluster-with-vsphere-storage-part-ii>Part II</a>, you should have a K3S Cluster stood up. In this Part we are going to add the all important Cloud Provider.</p><h2 id=step-1-prepare-nodes-for-vsphere-cloud-provider>Step 1: Prepare Nodes for vSphere Cloud Provider<a hidden class=anchor aria-hidden=true href=#step-1-prepare-nodes-for-vsphere-cloud-provider>#</a></h2><p>Before we can install the vSphere Cloud provider, there are couple configurations that need to be applied. You can read more about these requirements by heading over to the <a href=https://cloud-provider-vsphere.sigs.k8s.io/>VMWare documentation</a>.</p><h3 id=taint-nodes>Taint Nodes<a hidden class=anchor aria-hidden=true href=#taint-nodes>#</a></h3><p>The Cloud Provider is going to be installed on the Server (Master) Nodes. To ensure this happens correctly, we need to ensure the nodes are tainted correctly.</p><style type=text/css>.notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media(prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative}</style><div><svg width="0" height="0" display="none" xmlns="http://www.w3.org/2000/svg"><symbol id="tip-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379.0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628.0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628.0l-22.627 22.627c-6.248 6.248-6.248 16.379.0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z"/></symbol><symbol id="note-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405.0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346 7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373.0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884.0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="warning-notice" viewBox="0 0 576 512" preserveAspectRatio="xMidYMid meet"><path d="M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937.0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154.0l239.94 416.028zM288 354c-25.405.0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346 7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373.0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884.0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="info-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196.0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627.0 12 5.373 12 12v1e2h12c6.627.0 12 5.373 12 12v24z"/></symbol></svg></div><div class="notice info"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#info-notice"/></svg></span>Info</p><p>Not sure if this is a K3S quirk or just my luck, but additionally I had to reapply the Master and Worker roles to the Nodes for the DaemonSet to recognize the Role.</p></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>## TAINT SERVER (MASTER) NODES</span>
</span></span><span style=display:flex><span>kubectl taint nodes --selector<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;node-role.kubernetes.io/master&#39;</span> node-role.kubernetes.io/master<span style=color:#f92672>=</span>:NoSchedule
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## ADD ROLES TO SERVER (MASTER) NODES</span>
</span></span><span style=display:flex><span>kubectl label nodes --selector<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;node-role.kubernetes.io/master&#39;</span> node-role.kubernetes.io/master<span style=color:#f92672>=</span> --overwrite
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## TAINT AGENT (WORKER) NODES</span>
</span></span><span style=display:flex><span>kubectl taint nodes --selector<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;!node-role.kubernetes.io/master&#39;</span> node.cloudprovider.kubernetes.io/uninitialized<span style=color:#f92672>=</span>true:NoSchedule
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## ADD ROLES TO AGENT (WORKER) NODES</span>
</span></span><span style=display:flex><span>kubectl label nodes --selector<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;node-role.kubernetes.io/worker&#39;</span> node-role.kubernetes.io/worker<span style=color:#f92672>=</span> --overwrite
</span></span></code></pre></div><p>Once you have applied the Taints, you can verify they applied successfully by running this command;</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>## VALIDATE TAINTS</span>
</span></span><span style=display:flex><span>kubectl describe nodes | egrep <span style=color:#e6db74>&#34;Taints:|Name:&#34;</span>
</span></span></code></pre></div><p>If the taints applied successfully you should see all the Server (Master) Nodes with the Taint <code>node-role.kubernetes.io/master:NoSchedule</code> and all Agent (Worker) Nodes have the Taint <code>node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule</code></p><h3 id=configure-virtual-machine-settings>Configure Virtual Machine Settings<a hidden class=anchor aria-hidden=true href=#configure-virtual-machine-settings>#</a></h3><p>Another configuration item that needs to occur, is ensuring that each virtual machine’s hard disk (vmdk) is assigned a unique identifier (UUID). The easiest way to interact with the virtual machine settings is to use a command line utility called <code>govc</code>.</p><blockquote><p>govc is vSphere CLI provided by VMware and is built on top of govmoi. The CLI is designed to be a user friendly CLI alternative to the GUI and well suited for automation tasks. It also acts as a test harness for the govmomi APIs and provides working examples of how to use the APIs.</p><p>– <a href=https://github.com/vmware/govmomi/tree/master/govc><em>Govc Github</em></a></p></blockquote><p>To install the CLI on Mac, you can use Homebrew. To install govc run <code>brew install govc</code>. For other operating systems, please refer to the <a href=https://github.com/vmware/govmomi/tree/master/govc>documentation</a>.</p><h3 id=govc-setup>GOVC Setup<a hidden class=anchor aria-hidden=true href=#govc-setup>#</a></h3><p>Before we can use the utility we have to specify how <code>govc</code> connects to vSphere. In Mac and Linux, this is accomplished by setting environment variables.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>## CONFIGURE GOVC</span>
</span></span><span style=display:flex><span>export GOVC_URL<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;{{ URL-FOR-VCSA }}&#39;</span>
</span></span><span style=display:flex><span>export GOVC_USERNAME<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;administrator@vsphere.local&#39;</span>
</span></span><span style=display:flex><span>export GOVC_PASSWORD<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;{{ PASSWORD-FOR-ABOVE-ACCOUNT }}&#39;</span>
</span></span><span style=display:flex><span>export GOVC_INSECURE<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</span></span></code></pre></div><table><thead><tr><th><strong>Variable</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td>GOVC_URL</td><td>the URL for your vSphere (VCSA) instance</td></tr><tr><td>GOVC_USERNAME</td><td>the login account for vSphere</td></tr><tr><td>GOVC_PASSWORD</td><td>the password for the account specified</td></tr><tr><td>GOVC_INSECURE</td><td>used when self-signed certificates are in use on VCSA, suppresses certificate warnings</td></tr></tbody></table><h3 id=enable-diskuuid>Enable DiskUUID<a hidden class=anchor aria-hidden=true href=#enable-diskuuid>#</a></h3><p>At this point you should be able to utilize <code>govc</code> to query vSphere. The first command you can run is <code>govc ls</code>. This will list the any DataCenters you have configured and folders. You will need to enable DiskUUID on all the virtual machines in the cluster and to do this you will need to know the path to the virtual machine.</p><p>To find the path use the <code>govc ls</code> command followed by a path. Start with leaving it blank and keep drilling down until you find the paths to your virtual machines. For the example below, my final govc command looked like; <code>govc ls /Homelab/vm/Applications/Demo/</code></p><p>Enable DiskUUID on the virtual machines by running the following command. Outline below is how I applied it in my stack.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>## ADD DISK UUID FLAG</span>
</span></span><span style=display:flex><span>govc vm.change -e<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;disk.enableUUID=1&#34;</span> -vm<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;{{ PATH-TO-VM }}&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## EXAMPLE -- ADD DISK UUID </span>
</span></span><span style=display:flex><span>govc vm.change -e<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;disk.enableUUID=1&#34;</span> -vm<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;/Homelab/vm/Applications/Demo/MASTER-001&#39;</span>
</span></span><span style=display:flex><span>govc vm.change -e<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;disk.enableUUID=1&#34;</span> -vm<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;/Homelab/vm/Applications/Demo/MASTER-002&#39;</span>
</span></span><span style=display:flex><span>govc vm.change -e<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;disk.enableUUID=1&#34;</span> -vm<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;/Homelab/vm/Applications/Demo/MASTER-003&#39;</span>
</span></span><span style=display:flex><span>govc vm.change -e<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;disk.enableUUID=1&#34;</span> -vm<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;/Homelab/vm/Applications/Demo/WORKER-001&#39;</span>
</span></span><span style=display:flex><span>govc vm.change -e<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;disk.enableUUID=1&#34;</span> -vm<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;/Homelab/vm/Applications/Demo/WORKER-002&#39;</span>
</span></span><span style=display:flex><span>govc vm.change -e<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;disk.enableUUID=1&#34;</span> -vm<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;/Homelab/vm/Applications/Demo/WORKER-003&#39;</span>
</span></span></code></pre></div><h3 id=adding-providerid>Adding ProviderID<a hidden class=anchor aria-hidden=true href=#adding-providerid>#</a></h3><p>The final configuration change needed is to add a “ProviderID” to each of the nodes. Reading though the documentation, this ID needs to be unique but can be set to anything (within reason). Borrowing from the documentation, the easiest thing to do is to assign the virtual machine UUID as the ProviderID as these are always unique.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>## ADD PROVIDERID TO EACH NODE</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> vm in <span style=color:#66d9ef>$(</span>govc ls /Homelab/vm/Applications/Demo/<span style=color:#66d9ef>)</span>; <span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>MACHINE_INFO<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>govc vm.info -json -dc<span style=color:#f92672>=</span>Homelab -vm.ipath<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span>$vm<span style=color:#e6db74>&#34;</span> -e<span style=color:#f92672>=</span>true<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>VM_NAME<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>jq -r <span style=color:#e6db74>&#39; .VirtualMachines[] | .Name&#39;</span> <span style=color:#f92672>&lt;&lt;&lt;</span> $MACHINE_INFO | awk <span style=color:#e6db74>&#39;{print tolower($0)}&#39;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>VM_UUID<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span> jq -r <span style=color:#e6db74>&#39; .VirtualMachines[] | .Config.Uuid&#39;</span> <span style=color:#f92672>&lt;&lt;&lt;</span> $MACHINE_INFO | awk <span style=color:#e6db74>&#39;{print toupper($0)}&#39;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>kubectl patch node $VM_NAME.dodbrit.lab -p <span style=color:#e6db74>&#34;{\&#34;spec\&#34;:{\&#34;providerID\&#34;:\&#34;vsphere://</span>$VM_UUID<span style=color:#e6db74>\&#34;}}&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span>
</span></span></code></pre></div><p>For good measure, you can validate that the ProviderIDs were added correctly by running <code>kubectl describe nodes | egrep "ProviderID:|Name:"</code>. The expected outcome should be all of the nodes listed, with a ProviderID that starts with “vsphere”. Additionally, the IDs should all be unique.</p><h2 id=step-2-install-vsphere-cpi>Step 2: Install vSphere CPI<a hidden class=anchor aria-hidden=true href=#step-2-install-vsphere-cpi>#</a></h2><p>Now that we have our cluster up and running, and the nodes configured with additional information, we can finally install the vSphere Cloud Provider.</p><p>The first step is generate the required configuration file (<code>vsphere.conf</code>) and credentials (<code>cpi-secret.yaml</code>).</p><pre tabindex=0><code class=language-conf data-lang=conf># vsphere.conf

# Global properties in this section will be used for all specified vCenters unless overriden in VirtualCenter section.
global:
  # default https port
  port: 443
  # set insecureFlag to true if the vCenter uses a self-signed cert
  insecureFlag: true
  # settings for using k8s secret
  secretName: cpi-global-secret
  secretNamespace: kube-system

# vcenter section
vcenter:
  # arbitrary name for cluster
  demo:
    # ip or fqdn of vcsa
    server: 10.0.15.5
    # vSphere Datacenter Name
    datacenters:
      - Homelab
    # secret with credentials
    secretName: cpi-secret
    secretNamespace: kube-system
</code></pre><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># cpi-secret.yaml</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Secret</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>cpi-secret</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>kube-system</span>
</span></span><span style=display:flex><span><span style=color:#f92672>stringData</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>10.0.15.5.username</span>: <span style=color:#e6db74>&#34;administrator@vsphere.local&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>10.0.15.5.password</span>: <span style=color:#e6db74>&#34;{{ PASSWORD-TO-ACCOUNT }}&#34;</span>
</span></span></code></pre></div><p>To apply the vSphere configuration to the cluster, we will create a ConfigMap of the file. To do that you run the following command;</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl create configmap cloud-config --from-file<span style=color:#f92672>=</span>vsphere.conf --namespace<span style=color:#f92672>=</span>kube-system
</span></span></code></pre></div><p>This will create a ConfigMap in the <code>kube-system</code> namespace with all the items we defined. To add the login credentials, we just need to apply the Secret as that was defined as a Secret to begin with.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl create -f cpi-secret.yaml
</span></span></code></pre></div><p>Again for peace of mind, we can validate these applied;</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>## ENSURE CONFIGMAP WAS CREATED</span>
</span></span><span style=display:flex><span>kubectl get configmap cloud-config --namespace<span style=color:#f92672>=</span>kube-system
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## ENSURE SECRET WAS CREATED</span>
</span></span><span style=display:flex><span>kubectl get secret cpi-secret --namespace<span style=color:#f92672>=</span>kube-system
</span></span></code></pre></div><p>After you have verified that the ConfigMap and Secret was created, you can delete both of these files. These files have potentially sensitive information in them and its good practice to remove them.</p><p>Now we can deploy all the components of the vSphere Cloud Provider. We are going to apply them directly from the vSphere GitHub repository.</p><div class="notice note"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#note-notice"/></svg></span>Note</p><p>It is recommend that you review the files first and once you feel confident that the files are safe, you can then apply them</p></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>## CREATE ROLES</span>
</span></span><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes/cloud-provider-vsphere/master/manifests/controller-manager/cloud-controller-manager-roles.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## CREATE ROLE BINDINGS</span>
</span></span><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes/cloud-provider-vsphere/master/manifests/controller-manager/cloud-controller-manager-role-bindings.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## CREATE DAMEONSET</span>
</span></span><span style=display:flex><span>kubectl apply -f https://github.com/kubernetes/cloud-provider-vsphere/raw/master/manifests/controller-manager/vsphere-cloud-controller-manager-ds.yaml
</span></span></code></pre></div><p>And we can check that the Cloud Provider deployed successfully. You should see a <strong>vsphere-cloud-controller-manager</strong> running on each of your master nodes.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get pods --all-namespaces
</span></span></code></pre></div><p>Congratulations! We have just install the vSphere Cloud Provider within our cluster!</p><h2 id=step-3-install-vsphere-csi>Step 3: Install vSphere CSI<a hidden class=anchor aria-hidden=true href=#step-3-install-vsphere-csi>#</a></h2><p>Now that the Cloud Provider has been installed, we can turn the attention to the Cloud Storage Interface (CSI). Just like the Cloud Provider, we need to create some configuration files. Modify the file outlined below and save it as <code>csi-vsphere.conf</code>.</p><pre tabindex=0><code class=language-conf data-lang=conf>[Global]
cluster-id = &#34;k3s-cluster&#34;
user = &#34;administrator@vsphere.local&#34;
password = &#34;{{ PASSWORD-FOR-ACCOUNT }}&#34;
port = &#34;443&#34;
insecure-flag = &#34;1&#34;

[VirtualCenter &#34;{{ VCSA-IP-ADDRESS }}&#34;]
datacenters = &#34;Homelab&#34;

[Workspace]
server = &#34;{{ VCSA-IP-ADDRESS }}&#34;
datacenter = &#34;Homelab&#34;
default-datastore = &#34;{{ DEFAULT-VSPHERE-DATASTORE }}&#34;
resourcepool-path = &#34;{{ DATACENTER-NAME }}/Resources&#34;
folder = &#34;kubernetes&#34;

[Disk]
scsicontrollertype = pvscsi
</code></pre><p>The default-datastore field in the configuration file is important enough that it is included in the file, but will not be used once we configure the Storage Class. The Storage Class grants us the ability to define where the persistent storage will be save. Additionally, multiple Storage Class‘s can be defined that will allow for more granular storage based upon the deployment.</p><p>Unlike CPI, we are going to upload this configuration to Kubernetes via a Secret.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl create secret generic vsphere-config-secret --from-file<span style=color:#f92672>=</span>csi-vsphere.conf --namespace<span style=color:#f92672>=</span>kube-system
</span></span></code></pre></div><p>When then validate that the Secret created successfully …</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get secret vsphere-config-secret --namespace<span style=color:#f92672>=</span>kube-system
</span></span></code></pre></div><div class="notice note"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#note-notice"/></svg></span>Note</p><p>At this point, you made delete csi-vsphere.conf as it contains sensitive information.</p></div><p>Now we can deploy all the components of the vSphere Storage Provider. We are going to apply them directly from the vSphere GitHub repository.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>## DEFINE CLUSTER ROLES</span>
</span></span><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/vsphere-csi-driver/v2.2.0/manifests/v2.2.0/rbac/vsphere-csi-controller-rbac.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## DEFINE ROLE BINDINGS</span>
</span></span><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/vsphere-csi-driver/v2.2.0/manifests/v2.2.0/rbac/vsphere-csi-node-rbac.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## DEPLOY STORAGE DRIVERS (CONTROLLER)</span>
</span></span><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/vsphere-csi-driver/v2.2.0/manifests/v2.2.0/deploy/vsphere-csi-controller-deployment.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## DEPLOY STORAGE DRIVERS (DAMEONSET)</span>
</span></span><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/vsphere-csi-driver/v2.2.0/manifests/v2.2.0/deploy/vsphere-csi-node-ds.yaml
</span></span></code></pre></div><p>We can then validate the installation by checking the Pod deployment. It may take a few minutes for all of the pods to get created and start running.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get pods --namespace<span style=color:#f92672>=</span>kube-system
</span></span></code></pre></div><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p>At this point, and ensuring that everything went smoothly, you should have a Kubernetes cluster running with both vSphere CPI and CSI running and configured. In Part IV of this blog, we are going to define the storage class within the cluster and deploy a demo application.</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ul><li><a href=https://longhorn.io/>Rancher Labs Longhorn</a></li><li><a href=https://cloud-provider-vsphere.sigs.k8s.io/>vSphere Cloud Provider</a></li><li><a href=https://vsphere-csi-driver.sigs.k8s.io/>vSphere Storage Provider</a></li><li><a href=https://rancher.com/docs/k3s/latest/en/>Rancher Labs K3S</a></li><li><a href=https://kubernetes.io/docs/concepts/architecture/cloud-controller/>Kuberenetes Cloud Controllers</a></li><li><a href=https://vmware.github.io/photon/docs/>VMware Photon OS</a></li><li><a href=http://nginx.org/en/docs/http/load_balancing.html>NGINX Load Balancer</a></li><li><a href=https://github.com/vmware/govmomi/tree/master/govc>Govc Documentation</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://dodbrit.io/tags/rancher/>Rancher</a></li><li><a href=https://dodbrit.io/tags/kubernetes/>Kubernetes</a></li><li><a href=https://dodbrit.io/tags/storage/>Storage</a></li><li><a href=https://dodbrit.io/tags/k3s/>K3S</a></li><li><a href=https://dodbrit.io/tags/vmware/>VMWare</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share K3s Cluster With Vsphere Storage [Part III] on twitter" href="https://twitter.com/intent/tweet/?text=K3s%20Cluster%20With%20Vsphere%20Storage%20%5bPart%20III%5d&url=https%3a%2f%2fdodbrit.io%2fposts%2f2021-07-03%2fk3s-cluster-with-vsphere-storage-part-iii%2f&hashtags=Rancher%2cKubernetes%2cStorage%2cK3S%2cVMWare"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share K3s Cluster With Vsphere Storage [Part III] on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fdodbrit.io%2fposts%2f2021-07-03%2fk3s-cluster-with-vsphere-storage-part-iii%2f&title=K3s%20Cluster%20With%20Vsphere%20Storage%20%5bPart%20III%5d&summary=K3s%20Cluster%20With%20Vsphere%20Storage%20%5bPart%20III%5d&source=https%3a%2f%2fdodbrit.io%2fposts%2f2021-07-03%2fk3s-cluster-with-vsphere-storage-part-iii%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share K3s Cluster With Vsphere Storage [Part III] on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fdodbrit.io%2fposts%2f2021-07-03%2fk3s-cluster-with-vsphere-storage-part-iii%2f&title=K3s%20Cluster%20With%20Vsphere%20Storage%20%5bPart%20III%5d"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share K3s Cluster With Vsphere Storage [Part III] on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdodbrit.io%2fposts%2f2021-07-03%2fk3s-cluster-with-vsphere-storage-part-iii%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share K3s Cluster With Vsphere Storage [Part III] on whatsapp" href="https://api.whatsapp.com/send?text=K3s%20Cluster%20With%20Vsphere%20Storage%20%5bPart%20III%5d%20-%20https%3a%2f%2fdodbrit.io%2fposts%2f2021-07-03%2fk3s-cluster-with-vsphere-storage-part-iii%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share K3s Cluster With Vsphere Storage [Part III] on telegram" href="https://telegram.me/share/url?text=K3s%20Cluster%20With%20Vsphere%20Storage%20%5bPart%20III%5d&url=https%3a%2f%2fdodbrit.io%2fposts%2f2021-07-03%2fk3s-cluster-with-vsphere-storage-part-iii%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://dodbrit.io>DODBRIT</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>